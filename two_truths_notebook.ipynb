{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.manifold import spectral_embedding\n",
    "from sklearn.mixture import GaussianMixtureIC\n",
    "\n",
    "from graspologic.embed import AdjacencySpectralEmbed, LaplacianSpectralEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook we compare scikit-learn's spectral_embedding to our AdjacencySpectralEmbed and LaplacianSpectral Embed.\n",
    "# We provide four cases, in which LSE performs the best in the first and third case and ASE performs the best in the second and fourth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ari(n_verts, n_sims, B, embed_method, labels_true):\n",
    "    rows = []\n",
    "\n",
    "    for _ in tqdm(range(n_sims), desc=\"Simulations\", position=1, leave=True):\n",
    "        \n",
    "        #make probability matrix from block matrix\n",
    "        P = np.zeros((n_verts, n_verts))\n",
    "        P[0:int(n_verts/2),0:int(n_verts/2)] = B[0, 0]\n",
    "        P[int(n_verts/2):n_verts, int(n_verts/2):n_verts] = B[1, 1]\n",
    "        P[0:int(n_verts/2), int(n_verts/2):n_verts] = B[0, 1]\n",
    "        P[int(n_verts/2):n_verts, 0:int(n_verts/2)] = B[1, 0]\n",
    "\n",
    "        #make latent position matrix\n",
    "        U, S, V = np.linalg.svd(P)\n",
    "\n",
    "        #sample half the points from U\n",
    "        X = U[0:int(n_verts/2), 0:2] @ np.sqrt(np.diag(S[0:2]))\n",
    "\n",
    "        #sample half the points from V^T\n",
    "        Y = V.T[int(n_verts/2):n_verts, 0:2] @ np.sqrt(np.diag(S[0:2]))\n",
    "\n",
    "        #concatenate the two matrices to get the full latent position matrix\n",
    "        lat_mat = np.concatenate((X, Y), axis=0)\n",
    "\n",
    "        #get k_neighbors graph from latent position matrix (k=sqrt(n))\n",
    "        kn_graph = kneighbors_graph(lat_mat, n_neighbors=int(np.sqrt(n_verts)))\n",
    "        kn_graph = kn_graph.toarray()\n",
    "\n",
    "        #choose embedding method\n",
    "        if embed_method == \"ase\":\n",
    "            ase = AdjacencySpectralEmbed(n_components=2)\n",
    "            Xhat, Yhat = ase.fit_transform(kn_graph)\n",
    "        elif embed_method == \"lse\":\n",
    "            lse = LaplacianSpectralEmbed(n_components=2)\n",
    "            Xhat, Yhat = lse.fit_transform(kn_graph)\n",
    "        elif embed_method == \"sklearn\":\n",
    "            Xhat = spectral_embedding(kn_graph, n_components=2)\n",
    "\n",
    "\n",
    "        #concatenate Xhat and Yhat if using ase or lse\n",
    "        if embed_method == \"ase\" or embed_method == \"lse\":\n",
    "            Xhat = np.concatenate((Xhat, Yhat), axis=1)\n",
    "\n",
    "        #calculate the ARI score\n",
    "        gm_ic = GaussianMixtureIC(min_components=2, max_components=2, covariance_type=\"all\")\n",
    "        labels_mclust = gm_ic.fit_predict(Xhat)\n",
    "        ari = adjusted_rand_score(labels_true, labels_mclust)\n",
    "        result = {\n",
    "            \"test\": embed_method,\n",
    "            \"ari\": ari\n",
    "        }\n",
    "        rows.append(result)\n",
    "\n",
    "\n",
    "    results = pd.DataFrame(rows)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulations: 100%|██████████| 50/50 [00:04<00:00, 10.18it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:03<00:00, 13.96it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:03<00:00, 12.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ari</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ase</th>\n",
       "      <td>0.498978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lse</th>\n",
       "      <td>0.751601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>0.641565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ari\n",
       "test             \n",
       "ase      0.498978\n",
       "lse      0.751601\n",
       "sklearn  0.641565"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case 1: LSE does best\n",
    "n_verts_lse = 100\n",
    "n_sims = 50\n",
    "B_affinity = np.array([[0.050, 0.013], [0.013, 0.051]])\n",
    "labels_lse = int(n_verts_lse/2) * [0] + int(n_verts_lse/2) * [1]\n",
    "\n",
    "ari_aff_lse_df = calc_ari(n_verts = n_verts_lse, n_sims = n_sims, B = B_affinity, embed_method = \"lse\", labels_true = labels_lse)\n",
    "ari_aff_ase_df = calc_ari(n_verts = n_verts_lse, n_sims = n_sims, B = B_affinity, embed_method = \"ase\", labels_true = labels_lse)\n",
    "ari_aff_sklearn_df = calc_ari(n_verts = n_verts_lse, n_sims = n_sims, B = B_affinity, embed_method = \"sklearn\", labels_true = labels_lse)\n",
    "ari_aff_df = pd.concat([ari_aff_lse_df, ari_aff_ase_df, ari_aff_sklearn_df])\n",
    "\n",
    "#groupby the means for each embedding method across the simulations\n",
    "ari_aff_means = ari_aff_df.groupby([\"test\"]).mean()\n",
    "ari_aff_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulations: 100%|██████████| 50/50 [00:09<00:00,  5.19it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:09<00:00,  5.38it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:08<00:00,  6.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ari</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ase</th>\n",
       "      <td>0.724238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lse</th>\n",
       "      <td>0.002030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>0.339420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ari\n",
       "test             \n",
       "ase      0.724238\n",
       "lse      0.002030\n",
       "sklearn  0.339420"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case 2: ASE does best\n",
    "n_verts_ase = 500\n",
    "n_sims = 50\n",
    "B_core = np.array([[0.011, 0.027], [0.027, 0.079]])\n",
    "labels_ase = int(n_verts_ase/2) * [0] + int(n_verts_ase/2) * [1]\n",
    "\n",
    "ari_core_ase_df = calc_ari(n_verts = n_verts_ase, n_sims = n_sims, B = B_core, embed_method = \"ase\", labels_true = labels_ase)\n",
    "ari_core_lse_df = calc_ari(n_verts = n_verts_ase, n_sims = n_sims, B = B_core, embed_method = \"lse\", labels_true = labels_ase)\n",
    "ari_core_sklearn_df = calc_ari(n_verts = n_verts_ase, n_sims = n_sims, B = B_core, embed_method = \"sklearn\", labels_true = labels_ase)\n",
    "ari_core_df = pd.concat([ari_core_ase_df, ari_core_lse_df, ari_core_sklearn_df])\n",
    "ari_core_means = ari_core_df.groupby([\"test\"]).mean()\n",
    "ari_core_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulations: 100%|██████████| 50/50 [00:04<00:00, 10.68it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:03<00:00, 13.11it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:03<00:00, 13.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ari</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ase</th>\n",
       "      <td>0.576058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lse</th>\n",
       "      <td>0.789817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>0.214142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ari\n",
       "test             \n",
       "ase      0.576058\n",
       "lse      0.789817\n",
       "sklearn  0.214142"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case 2: LSE does best\n",
    "n_verts_lse = 100\n",
    "n_sims = 50\n",
    "B_core = np.array([[0.011, 0.027], [0.027, 0.079]])\n",
    "labels_lse = int(n_verts_lse/2) * [0] + int(n_verts_lse/2) * [1]\n",
    "\n",
    "ari_aff_lse_df = calc_ari(n_verts = n_verts_lse, n_sims = n_sims, B = B_core, embed_method = \"lse\", labels_true = labels_lse)\n",
    "ari_aff_ase_df = calc_ari(n_verts = n_verts_lse, n_sims = n_sims, B = B_core, embed_method = \"ase\", labels_true = labels_lse)\n",
    "ari_aff_sklearn_df = calc_ari(n_verts = n_verts_lse, n_sims = n_sims, B = B_core, embed_method = \"sklearn\", labels_true = labels_lse)\n",
    "ari_aff_df = pd.concat([ari_aff_lse_df, ari_aff_ase_df, ari_aff_sklearn_df])\n",
    "\n",
    "#groupby the means for each embedding method across the simulations\n",
    "ari_aff_means = ari_aff_df.groupby([\"test\"]).mean()\n",
    "ari_aff_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulations: 100%|██████████| 50/50 [00:07<00:00,  6.43it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:07<00:00,  6.80it/s]\n",
      "Simulations: 100%|██████████| 50/50 [00:06<00:00,  7.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ari</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ase</th>\n",
       "      <td>0.495721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lse</th>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>0.247929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ari\n",
       "test             \n",
       "ase      0.495721\n",
       "lse      0.003095\n",
       "sklearn  0.247929"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#case 4: ASE does best\n",
    "n_verts_ase = 500\n",
    "n_sims = 50\n",
    "B_affinity = np.array([[0.050, 0.013], [0.013, 0.051]])\n",
    "labels_ase = int(n_verts_ase/2) * [0] + int(n_verts_ase/2) * [1]\n",
    "\n",
    "ari_core_ase_df = calc_ari(n_verts = n_verts_ase, n_sims = n_sims, B = B_affinity, embed_method = \"ase\", labels_true = labels_ase)\n",
    "ari_core_lse_df = calc_ari(n_verts = n_verts_ase, n_sims = n_sims, B = B_affinity, embed_method = \"lse\", labels_true = labels_ase)\n",
    "ari_core_sklearn_df = calc_ari(n_verts = n_verts_ase, n_sims = n_sims, B = B_affinity, embed_method = \"sklearn\", labels_true = labels_ase)\n",
    "ari_core_df = pd.concat([ari_core_ase_df, ari_core_lse_df, ari_core_sklearn_df])\n",
    "ari_core_means = ari_core_df.groupby([\"test\"]).mean()\n",
    "ari_core_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
